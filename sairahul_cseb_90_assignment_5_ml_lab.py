# -*- coding: utf-8 -*-
"""SaiRahul CSEB 90 Assignment 5 ML Lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wQDAurec99b0Z9CFGQ9zgQzek9wf4xig
"""





pip install scikit-plot











# Install necessary libraries
!pip install scikit-plot
!pip install imbalanced-learn

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from numpy import set_printoptions
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, f1_score, precision_score, recall_score
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.neighbors import KNeighborsClassifier
import scikitplot as skplt

# Reading the dataset
df = pd.read_csv("online_shoppers_intention.csv")
print(df.head())
print(df.info())
print(df.isnull().sum())

# Displaying summary statistics
print(df.describe().transpose())

# Plotting histograms and count plots
sns.histplot(data=df, x='ProductRelated', bins=10)
plt.show()

sns.countplot(data=df, x='Month')
plt.show()

sns.countplot(data=df, x='Revenue')
plt.show()

# Handle non-numeric data for correlation calculation
df_numeric = df.select_dtypes(include=[np.number])

# Correlation matrix
print(df_numeric.corr())

# Heatmap of the correlation matrix
sns.heatmap(df_numeric.corr(), annot=True, cmap="coolwarm")
plt.show()

# Box Plot
sns.boxplot(data=df, x='VisitorType', y='BounceRates')
plt.show()

# Feature Engineering
X = df.iloc[:, :-1]  # Selecting all columns except the last one as features
y = df.iloc[:, -1]   # Selecting the last column as the target

# Encode categorical features if necessary
X = pd.get_dummies(X)

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)

# Sampling
print("Original class distribution:")
print(y.value_counts())

# Applying SMOTE for oversampling
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

print("Resampled class distribution:")
print(y_resampled.value_counts())

# Normalization
# Fit the scaler on training data
norm = MinMaxScaler().fit(X_train)

# Transform training and testing data
X_train_norm = norm.transform(X_train)
X_test_norm = norm.transform(X_test)

# Building and training the model
model = KNeighborsClassifier(n_neighbors=11)
model2 = KNeighborsClassifier(n_neighbors=11)
model.fit(X_train_norm, y_train)
model2.fit(X_resampled, y_resampled)

# Predictions
y_pred = model.predict(X_test_norm)
y_pred2 = model2.predict(X_test_norm)

# Plotting ROC Curve and calculating AUC
y_pred_proba = model.predict_proba(X_test_norm)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)

y_pred_proba2 = model2.predict_proba(X_test_norm)[:, 1]
auc2 = roc_auc_score(y_test, y_pred_proba2)

# Using scikit-plot for better ROC curve visualization
skplt.metrics.plot_roc(y_test, model.predict_proba(X_test_norm), title="ROC Curve without Oversampling")
skplt.metrics.plot_roc(y_test, model2.predict_proba(X_test_norm), title="ROC Curve with Oversampling", plot_micro=False, plot_macro=False)

plt.show()

# Printing evaluation metrics
print("Accuracy score without oversampling:", accuracy_score(y_test, y_pred))
print("F1 score without oversampling:", f1_score(y_test, y_pred))
print("Precision without oversampling:", precision_score(y_test, y_pred))
print("Recall without oversampling:", recall_score(y_test, y_pred))

print()

print("Accuracy score with oversampling:", accuracy_score(y_test, y_pred2))
print("F1 score with oversampling:", f1_score(y_test, y_pred2))
print("Precision with oversampling:", precision_score(y_test, y_pred2))
print("Recall with oversampling:", recall_score(y_test, y_pred2))





